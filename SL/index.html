<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Statistcal learning - software notes</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/Bash.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/HTML.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/Java.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/JavaScript.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/Perl.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/Python.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/R.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/rust.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/yaml.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">
            <div class="container">
                <a class="navbar-brand" href="..">software notes</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link"></a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Genetic analysis <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../AA/" class="dropdown-item">Association analysis</a>
</li>
                                    
<li>
    <a href="../CRISPR/" class="dropdown-item">CRISPR</a>
</li>
                                    
<li>
    <a href="../misc/" class="dropdown-item">Miscellaneous software</a>
</li>
                                    
<li>
    <a href="../LRS/" class="dropdown-item">Long-read sequencing</a>
</li>
                                    
<li>
    <a href="../NGS/" class="dropdown-item">NGS</a>
</li>
                                    
<li>
    <a href="../pharmacogenomics/" class="dropdown-item">Pharmacogenomics</a>
</li>
                                    
<li>
    <a href="../prottrans/" class="dropdown-item">Proteome and transcriptome</a>
</li>
                                    
<li>
    <a href="../single-cell/" class="dropdown-item">Single-cell analysis</a>
</li>
                                </ul>
                            </li>
                            <li class="navitem active">
                                <a href="./" class="nav-link">Statistcal learning</a>
                            </li>
                            <li class="navitem">
                                <a href="../AI/" class="nav-link">Artificial intelligence</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../single-cell/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../AI/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/jinghuazhao/software-notes" class="nav-link"><i class="fa fa-github"></i> GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#statistcal-learning" class="nav-link">Statistcal learning</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#deep-learning" class="nav-link">Deep learning</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#machine-learning" class="nav-link">Machine learning</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#statistical-learning-and-islr" class="nav-link">Statistical learning and ISLR</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#data-repositories" class="nav-link">Data repositories</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#python-code-examples" class="nav-link">Python Code Examples</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#r-code-example" class="nav-link">R code example</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="statistcal-learning">Statistcal learning</h1>
<h2 id="deep-learning">Deep learning</h2>
<h3 id="autoencoder">Autoencoder</h3>
<ul>
<li>Four types, <a href="https://github.com/nathanhubens/Autoencoders">https://github.com/nathanhubens/Autoencoders</a>.</li>
<li><a href="http://yann.lecun.com/exdb/mnist/">The notMNIST dataset</a>, <a href="https://www.datacamp.com/community/tutorials/autoencoder-keras-tutorial">https://www.datacamp.com/community/tutorials/autoencoder-keras-tutorial</a>.</li>
<li><a href="https://www.kaggle.com/mlg-ulb/creditcardfraud">Credit fraud example</a>, <a href="https://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/">https://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/</a>.</li>
<li><a href="https://www.r-bloggers.com/pca-vs-autoencoders-for-dimensionality-reduction/">PCA vs autoencoder</a></li>
</ul>
<h2 id="machine-learning">Machine learning</h2>
<p>(as it is called in computer science literature)</p>
<ul>
<li>Apress, <a href="https://github.com/apress">https://github.com/apress</a></li>
<li>Packt, <a href="https://github.com/PacktPublishing">https://github.com/PacktPublishing</a></li>
</ul>
<blockquote>
<p>Lantz B (2023) Machine Learning with R, 4e, Packt, <a href="https://github.com/PacktPublishing/Machine-Learning-with-R-Fourth-Edition">https://github.com/PacktPublishing/Machine-Learning-with-R-Fourth-Edition</a>.</p>
</blockquote>
<h2 id="statistical-learning-and-islr">Statistical learning and <a href="https://CRAN.R-project.org/package=ISLR">ISLR</a></h2>
<blockquote>
<p>Hastie T, Tibshirani R, Friedman J (2009). <a href="https://www.springer.com/gb/book/9780387848570">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</a>. Springer.</p>
<p>James G, Witten D, Hastie T, Tibshirani R (2013). <a href="http://www-bcf.usc.edu/~gareth/ISL/">An Introduction to Statistical Learning with Applications in R</a>. Springer.</p>
<p>James G, Witten D, Hastie T, Tibshirani R (2021). <a href="https://www.statlearning.com/">An Introduction to Statistical Learning with Applications in R, 2e</a>, Springer.</p>
<p>Chollet F, Allaire JJ (2017). <a href="https://livebook.manning.com/book/deep-learning-with-r/">Deep Learning with R</a>, Manning. <a href="https://www.manning.com/books/deep-learning-with-r">Source code</a>, <a href="https://github.com/jjallaire/deep-learning-with-r-notebooks">GitHub</a>.</p>
</blockquote>
<h2 id="data-repositories">Data repositories</h2>
<ul>
<li>ImageNet, <a href="https://www.image-net.org/">https://www.image-net.org/</a></li>
<li>UC Irvine Machine Learning Repository, <a href="https://archive.ics.uci.edu/">https://archive.ics.uci.edu/</a></li>
</ul>
<h2 id="python-code-examples">Python Code Examples</h2>
<p>From: Machine Learning Fundamentals Handbook – Key Concepts, Algorithms, and Python Code Examples, </p>
<p>Web: <a href="https://www.freecodecamp.org/news/machine-learning-handbook/">https://www.freecodecamp.org/news/machine-learning-handbook/</a></p>
<p>Changes are made a couple of places, e.g., Bagging, where option <code>base_estimator</code> is replaced with <code>estimator</code> as in
<code>BaggingRegressor(estimator=base_estimator, n_estimators=10, random_state=42)</code>, AdaBoost, the missing line is added:
<code>from sklearn.ensemble import GradientBoostingRegressor</code>. Now it is also possible to convert the MarkDown document
into a Jupyter notebook (.ipynb).</p>
<h3 id="linear-regression">Linear Regression</h3>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Sample Data
stamps_bought = np.array([1, 3, 5, 7, 9]).reshape((-1, 1))  # Reshaping to make it a 2D array
amount_spent = np.array([2, 6, 8, 12, 18])

# Creating a Linear Regression Model
model = LinearRegression()

# Training the Model
model.fit(stamps_bought, amount_spent)

# Predictions
next_month_stamps = 10
predicted_spend = model.predict([[next_month_stamps]])

# Plotting
plt.scatter(stamps_bought, amount_spent, color='blue')
plt.plot(stamps_bought, model.predict(stamps_bought), color='red')
plt.title('Stamps Bought vs Amount Spent')
plt.xlabel('Stamps Bought')
plt.ylabel('Amount Spent ($)')
plt.grid(True)
plt.show()

# Displaying Prediction
print(f&quot;If Alex buys {next_month_stamps} stamps next month, they will likely spend ${predicted_spend[0]:.2f}.&quot;)
</code></pre>
<h3 id="logistic-regression">Logistic Regression</h3>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Sample Data
pages = np.array([100, 150, 200, 250, 300, 350, 400, 450, 500]).reshape(-1, 1)
likes = np.array([0, 1, 1, 1, 0, 0, 0, 0, 0])  # 1: Like, 0: Dislike

# Creating a Logistic Regression Model
model = LogisticRegression()

# Training the Model
model.fit(pages, likes)

# Predictions
predict_book_pages = 260
predicted_like = model.predict([[predict_book_pages]])

# Plotting
plt.scatter(pages, likes, color='forestgreen')
plt.plot(pages, model.predict_proba(pages)[:, 1], color='darkred')
plt.title('Book Pages vs Like/Dislike')
plt.xlabel('Number of Pages')
plt.ylabel('Likelihood of Liking')
plt.axvline(x=predict_book_pages, color='green', linestyle='--')
plt.axhline(y=0.5, color='grey', linestyle='--')
plt.show()

# Displaying Prediction
print(f&quot;Jenny will {'like' if predicted_like[0] == 1 else 'not like'} a book of {predict_book_pages} pages.&quot;)
</code></pre>
<h3 id="linear-discrimant-analysis">Linear Discrimant Analysis</h3>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

# Sample Data
# [size, sweetness]
fruits_features = np.array([[3, 7], [2, 8], [3, 6], [4, 7], [1, 4], [2, 3], [3, 2], [4, 3]])
fruits_likes = np.array([1, 1, 1, 1, 0, 0, 0, 0])  # 1: Like, 0: Dislike

# Creating an LDA Model
model = LinearDiscriminantAnalysis()

# Training the Model
model.fit(fruits_features, fruits_likes)

# Prediction
new_fruit = np.array([[2.5, 6]])  # [size, sweetness]
predicted_like = model.predict(new_fruit)

# Plotting
plt.scatter(fruits_features[:, 0], fruits_features[:, 1], c=fruits_likes, cmap='viridis', marker='o')
plt.scatter(new_fruit[:, 0], new_fruit[:, 1], color='darkred', marker='x')
plt.title('Fruits Enjoyment Based on Size and Sweetness')
plt.xlabel('Size')
plt.ylabel('Sweetness')
plt.show()

# Displaying Prediction
print(f&quot;Sarah will {'like' if predicted_like[0] == 1 else 'not like'} a fruit of size {new_fruit[0, 0]} and sweetness {new_fruit[0, 1]}.&quot;)
</code></pre>
<h3 id="naive-bayes">Naive Bayes</h3>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.naive_bayes import GaussianNB

# Sample Data
# [movie_length, genre_code] (assuming genre is coded as: 0 for Action, 1 for Romance, etc.)
movies_features = np.array([[120, 0], [150, 1], [90, 0], [140, 1], [100, 0], [80, 1], [110, 0], [130, 1]])
movies_likes = np.array([1, 1, 0, 1, 0, 1, 0, 1])  # 1: Like, 0: Dislike

# Creating a Naive Bayes Model
model = GaussianNB()

# Training the Model
model.fit(movies_features, movies_likes)

# Prediction
new_movie = np.array([[100, 1]])  # [movie_length, genre_code]
predicted_like = model.predict(new_movie)

# Plotting
plt.scatter(movies_features[:, 0], movies_features[:, 1], c=movies_likes, cmap='viridis', marker='o')
plt.scatter(new_movie[:, 0], new_movie[:, 1], color='darkred', marker='x')
plt.title('Movie Likes Based on Length and Genre')
plt.xlabel('Movie Length (min)')
plt.ylabel('Genre Code')
plt.show()

# Displaying Prediction
print(f&quot;Tom will {'like' if predicted_like[0] == 1 else 'not like'} a {new_movie[0, 0]}-min long movie of genre code {new_movie[0, 1]}.&quot;)
</code></pre>
<h3 id="decision-trees">Decision Trees</h3>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor, plot_tree

# Sample Data
# [hours_studied]
study_hours = np.array([1, 2, 3, 4, 5, 6, 7, 8]).reshape(-1, 1)
test_scores = np.array([50, 55, 70, 80, 85, 90, 92, 98])

# Creating a Decision Tree Regression Model
model = DecisionTreeRegressor(max_depth=3)

# Training the Model
model.fit(study_hours, test_scores)

# Prediction
new_study_hour = np.array([[5.5]])  # example of hours studied
predicted_score = model.predict(new_study_hour)

# Plotting the Decision Tree
plt.figure(figsize=(12, 8))
plot_tree(model, filled=True, rounded=True, feature_names=[&quot;Study Hours&quot;])
plt.title('Decision Tree Regressor Tree')
plt.show()

# Plotting Study Hours vs. Test Scores
plt.scatter(study_hours, test_scores, color='darkred')
plt.plot(np.sort(study_hours, axis=0), model.predict(np.sort(study_hours, axis=0)), color='orange')
plt.scatter(new_study_hour, predicted_score, color='green')
plt.title('Study Hours vs Test Scores')
plt.xlabel('Study Hours')
plt.ylabel('Test Scores')
plt.grid(True)
plt.show()

# Displaying Prediction
print(f&quot;Predicted test score for {new_study_hour[0, 0]} hours of study: {predicted_score[0]:.2f}.&quot;)
</code></pre>
<h3 id="bagging">Bagging</h3>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import BaggingRegressor
from sklearn.tree import DecisionTreeRegressor, plot_tree  # Ensure plot_tree is imported
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Sample Data
clients_data = np.array([[2000, 60], [2500, 45], [1800, 75], [2200, 50], [2100, 62], [2300, 70], [1900, 55], [2000, 65]])
weight_loss = np.array([3, 2, 4, 3, 3.5, 4.5, 3.7, 4.2])

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(clients_data, weight_loss, test_size=0.25, random_state=42)

# Creating a Bagging Model
base_estimator = DecisionTreeRegressor(max_depth=4)
model = BaggingRegressor(estimator=base_estimator, n_estimators=10, random_state=42)

# Training the Model
model.fit(X_train, y_train)

# Prediction &amp; Evaluation
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)

# Displaying Prediction and Evaluation
print(f&quot;True weight loss: {y_test}&quot;)
print(f&quot;Predicted weight loss: {y_pred}&quot;)
print(f&quot;Mean Squared Error: {mse:.2f}&quot;)

# Visualizing One of the Base Estimators (if desired)
plt.figure(figsize=(12, 8))
tree = model.estimators_[0]
plt.title('One of the Base Decision Trees from Bagging')
plot_tree(tree, filled=True, rounded=True, feature_names=[&quot;Calorie Intake&quot;, &quot;Workout Duration&quot;])
plt.show()
</code></pre>
<h3 id="random-forest">Random Forest</h3>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Expanded Data
plants_features = np.array([
    [3, 1], [2, 2], [4, 1], [3, 2], [5, 1], [2, 2], [4, 1], [5, 2],
    [3, 1], [4, 2], [5, 1], [3, 2], [2, 1], [4, 2], [3, 1], [4, 2],
    [5, 1], [2, 2], [3, 1], [4, 2], [2, 1], [5, 2], [3, 1], [4, 2]
])
plants_species = np.array([
    0, 1, 0, 1, 0, 1, 0, 1,
    0, 1, 0, 1, 0, 1, 0, 1,
    0, 1, 0, 1, 0, 1, 0, 1
])

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(plants_features, plants_species, test_size=0.25, random_state=42)

# Creating a Random Forest Model
model = RandomForestClassifier(n_estimators=10, random_state=42)

# Training the Model
model.fit(X_train, y_train)

# Prediction &amp; Evaluation
y_pred = model.predict(X_test)
classification_rep = classification_report(y_test, y_pred)

# Displaying Prediction and Evaluation
print(&quot;Classification Report:&quot;)
print(classification_rep)

# Scatter Plot Visualizing Classes
plt.figure(figsize=(8, 4))
for species, marker, color in zip([0, 1], ['o', 's'], ['forestgreen', 'darkred']):
    plt.scatter(plants_features[plants_species == species, 0],
                plants_features[plants_species == species, 1],
                marker=marker, color=color, label=f'Species {species}')

plt.xlabel('Leaf Size')
plt.ylabel('Flower Color (coded)')
plt.title('Scatter Plot of Species')
plt.legend()
plt.tight_layout()
plt.show()

# Visualizing Feature Importances
plt.figure(figsize=(8, 4))
features_importance = model.feature_importances_
features = [&quot;Leaf Size&quot;, &quot;Flower Color&quot;]
plt.barh(features, features_importance, color = &quot;darkred&quot;)
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importance')
plt.show()
</code></pre>
<h3 id="boosting">Boosting</h3>
<h4 id="adaboost">AdaBoost</h4>
<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error

# Seed for reproducibility
np.random.seed(42)

# Generate synthetic data
num_samples = 200
num_rooms = np.random.randint(3, 10, num_samples)
house_age = np.random.randint(1, 100, num_samples)
noise = np.random.normal(0, 50, num_samples)

# Assume a linear relation with price = 50*rooms + 0.5*age + noise
price = 50*num_rooms + 0.5*house_age + noise

# Create DataFrame
data = pd.DataFrame({'num_rooms': num_rooms, 'house_age': house_age, 'price': price})

# Plot
plt.scatter(data['num_rooms'], data['price'], label='Num Rooms vs Price', color = 'forestgreen')
plt.scatter(data['house_age'], data['price'], label='House Age vs Price', color = 'darkred')
plt.xlabel('Feature Value')
plt.ylabel('Price')
plt.legend()
plt.title('Scatter Plots of Features vs Price')
plt.show()

# Splitting data into training and testing sets
X = data[['num_rooms', 'house_age']]
y = data['price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train AdaBoost Regressor model
model_ab = AdaBoostRegressor(n_estimators=100, random_state=42)
model_ab.fit(X_train, y_train)

# Predictions
predictions = model_ab.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, predictions)
rmse = np.sqrt(mse)
print(f&quot;Mean Squared Error: {mse:.2f}&quot;)
print(f&quot;Root Mean Squared Error: {rmse:.2f}&quot;)

# Visualization: Actual vs Predicted Prices
plt.scatter(y_test, predictions, color = 'darkred')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=3)
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Actual vs Predicted House Prices with AdaBoost')
plt.show()
</code></pre>
<h4 id="gradient-boosting-model">Gradient Boosting Model</h4>
<pre><code class="language-python"># Initialize and train Gradient Boosting Regressor model
model_gbm = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=42)
model_gbm.fit(X_train, y_train)

# Predictions
predictions = model_gbm.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, predictions)
rmse = np.sqrt(mse)
print(f&quot;Mean Squared Error: {mse:.2f}&quot;)
print(f&quot;Root Mean Squared Error: {rmse:.2f}&quot;)

# Visualization: Actual vs Predicted Prices
plt.scatter(y_test, predictions, color = 'orange')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=3)
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Actual vs Predicted House Prices with GBM')
plt.show()
</code></pre>
<h4 id="extreme-gradient-boosting-xgboost">Extreme Gradient Boosting (XGBoost)</h4>
<pre><code class="language-python">import xgboost as xgb

# Initialize and train XGBoost model
model_xgb = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators = 100, seed = 42)
model_xgb.fit(X_train, y_train)

# Predictions
predictions = model_xgb.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, predictions)
rmse = np.sqrt(mse)
print(f&quot;Mean Squared Error: {mse:.2f}&quot;)
print(f&quot;Root Mean Squared Error: {rmse:.2f}&quot;)

# Visualization: Actual vs Predicted Prices
plt.scatter(y_test, predictions, color=&quot;forestgreen&quot;)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=3)
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Actual vs Predicted House Prices with XGBoost')
plt.show()
</code></pre>
<h2 id="r-code-example">R code example</h2>
<h3 id="confusion-matrix">Confusion matrix</h3>
<pre><code class="language-r">library(caret)

# Example data
set.seed(123)
data &lt;- data.frame(
  Actual = sample(c(&quot;True&quot;, &quot;False&quot;), 100, replace = TRUE),
  Prediction = sample(c(&quot;True&quot;, &quot;False&quot;), 100, replace = TRUE)
)

# Create confusion matrix
cm &lt;- confusionMatrix(as.factor(data$Prediction), as.factor(data$Actual), positive = &quot;True&quot;)
print(cm)
</code></pre></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../js/jquery-3.6.0.min.js"></script>
        <script src="../js/bootstrap.min.js"></script>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js"></script>
        <script src="../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
